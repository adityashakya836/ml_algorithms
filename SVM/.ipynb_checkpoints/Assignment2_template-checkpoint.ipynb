{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset:\n",
    "You will be working with two datasets: Train and Test, both containing images of 40 individuals. Each dataset has been preprocessed for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create PCA function that takes two inputs: dataset, and k= number of principle component, and return the transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pca(Data,k):\n",
    "    \"Build this function\"\n",
    "    mean_vector = np.mean(Data, axis=0)\n",
    "    centered_data = Data - mean_vector\n",
    "\n",
    "    # Step 2: Calculate the Covariance Matrix\n",
    "    covariance_matrix = np.cov(centered_data, rowvar=False)\n",
    "\n",
    "    # Step 3: Find Eigenvalues and Eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "    # Step 4: Sort Eigenvalues and Eigenvectors\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[sorted_indices]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "    # Step 5: Select the top k eigenvectors as principal components\n",
    "    principal_components = eigenvectors[:, :k]\n",
    "\n",
    "    # Step 6: Project the data onto the selected principal components\n",
    "    X_reduced = np.dot(principal_components.transpose(),centered_data.transpose()).transpose()\n",
    "\n",
    "#     projected_data = np.dot(centered_data, principal_components)\n",
    "\n",
    "    return X_reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pca(Data , k):\n",
    "     \n",
    "    #Step-1\n",
    "    X_meaned = Data - np.mean(Data , axis = 0)\n",
    "     \n",
    "    #Step-2\n",
    "    cov_mat = np.cov(X_meaned , rowvar = False)\n",
    "     \n",
    "    #Step-3\n",
    "    eigen_values , eigen_vectors = np.linalg.eigh(cov_mat)\n",
    "     \n",
    "    #Step-4\n",
    "    sorted_index = np.argsort(eigen_values)[::-1]\n",
    "    sorted_eigenvalue = eigen_values[sorted_index]\n",
    "    sorted_eigenvectors = eigen_vectors[:,sorted_index]\n",
    "     \n",
    "    #Step-5\n",
    "    eigenvector_subset = sorted_eigenvectors[:,0:k]\n",
    "     \n",
    "    #Step-6\n",
    "    X_reduced = np.dot(eigenvector_subset.transpose() , X_meaned.transpose() ).transpose()\n",
    "     \n",
    "    return X_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read your TrainData and Test data. Try to remove the last column of the training data and assign it to one variable, do same thing for the TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the code here\n",
    "df_train = pd.read_csv('TrainData.csv')\n",
    "X_train = df_train.iloc[:,:-1]\n",
    "X_test = df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('TestData.csv')\n",
    "y_train = df_test.iloc[:,:-1]\n",
    "y_test = df_test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply my_pca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the code here\n",
    "result = my_pca(X_train,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_y = my_pca(y_train,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply pca using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the code here\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "scaling=StandardScaler()\n",
    "Scaled_data=scaling.fit_transform(X_train)\n",
    "Scaled_data_y = scaling.fit_transform(y_train)\n",
    "\n",
    "principal=PCA(n_components=3)\n",
    "\n",
    "x=principal.fit_transform(Scaled_data)\n",
    "y = principal.fit_transform(Scaled_data_y)\n",
    "\n",
    "\n",
    "# plt.figure(figsize = (6,6))\n",
    "# sb.scatterplot(data = principal_df , x = 'PC1',y = 'PC2' , hue = 'T_10305' , s = 60 , palette= 'icefire')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create kernel PCA function that takes two inputs: dataset, and k= number of principle component, and return the transform data. In addition, you need to create three other function one for rbf_kernel, one for polynomial_kernel, and one for linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rbf_kernel(x, y, gamma=1.0):\n",
    "    return np.exp(-gamma * np.linalg.norm(x - y) ** 2)\n",
    "\n",
    "def poly_kernel(x, y, degree=3):\n",
    "    return (np.dot(x, y) + 1) ** degree\n",
    "\n",
    "def linear_kernel(x, y):\n",
    "    \n",
    "    return np.dot(x, y)\n",
    "\n",
    "def my_kpca(data, n_components, kernel_type='rbf', kernel_param=1.0):\n",
    "    \"\"\"\n",
    "    Kernel Principal Component Analysis (KPCA) function.\n",
    "\n",
    "    Parameters:\n",
    "    - data: Input data as an ndarray of shape (n_samples, n_features).\n",
    "    - n_components: Number of principal components to retain.\n",
    "    - kernel_type: Type of kernel ('rbf', 'poly', or 'linear').\n",
    "    - kernel_param: Kernel parameter (e.g., gamma for RBF, degree for polynomial).\n",
    "\n",
    "    Returns:\n",
    "    - Transformed data in the KPCA space.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_samples, n_features = data.shape\n",
    "    K = np.zeros((n_samples, n_samples))\n",
    "\n",
    "    # Calculate the kernel matrix\n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_samples):\n",
    "            if kernel_type == 'rbf':\n",
    "                K[i, j] = rbf_kernel(data[i], data[j], gamma=kernel_param)\n",
    "            elif kernel_type == 'poly':\n",
    "                K[i, j] = poly_kernel(data[i], data[j], degree=kernel_param)\n",
    "            elif kernel_type == 'linear':\n",
    "                K[i, j] = linear_kernel(data[i], data[j])\n",
    "\n",
    "    # Center the kernel matrix\n",
    "    one_n = np.ones((n_samples, n_samples)) / n_samples\n",
    "    K_centered = K - np.dot(one_n, K) - np.dot(K, one_n) + np.dot(np.dot(one_n, K), one_n)\n",
    "\n",
    "    # Compute eigenvalues and eigenvectors of the centered kernel matrix\n",
    "    eigvals, eigvecs = np.linalg.eigh(K_centered)\n",
    "\n",
    "    # Sort eigenvalues and eigenvectors in descending order\n",
    "    sorted_indices = np.argsort(eigvals)[::-1]\n",
    "    eigvals = eigvals[sorted_indices]\n",
    "    eigvecs = eigvecs[:, sorted_indices]\n",
    "\n",
    "    # Select the top n_components eigenvectors\n",
    "    eigvecs = eigvecs[:, :n_components]\n",
    "\n",
    "    # Project the data into KPCA space\n",
    "    kpca_data = np.dot(K_centered, eigvecs)\n",
    "\n",
    "    return kpca_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply my_kpca on the Train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_kpca = my_kpca(train_x.to_numpy(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Kpca using sklearn on Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build your code here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import KernelPCA\n",
    "stndS = StandardScaler()\n",
    "XTrain = stndS.fit_transform(train_x)\n",
    "XTest = stndS.fit_transform(test_x)\n",
    "\n",
    "Kernel_pca = KernelPCA(n_components = 2, kernel= \"rbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build your code her \n",
    "XTrain = Kernel_pca.fit_transform(XTrain)\n",
    "XTest = Kernel_pca.transform(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can use the functions below as your classifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate distance between two points\n",
    "def dis(x1, x2):\n",
    "    return np.linalg.norm(x1 - x2)\n",
    "\n",
    "# Function to perform classification \n",
    "def myclassifier(Train, Trainlabel, Test):\n",
    "    \" Train is the training data\"\n",
    "    \" Trainlabel is the training labels\"\n",
    "    \" Test is the testing data\"\n",
    "    pred = []\n",
    "\n",
    "    for testpoint in Test:\n",
    "        pred_dis = []\n",
    "        for trainpoint in Train:\n",
    "            pred_dis.append(dis(testpoint, trainpoint))\n",
    "\n",
    "        pred.append(np.argmin(pred_dis))  \n",
    "\n",
    "    return np.array(pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below function is to calculte the accuracy , you can use this function to get the accuracy of pca and kpca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(true_labels, predicted_labels):\n",
    "    # Ensure that the true labels and predicted labels have the same length\n",
    "    if len(true_labels) != len(predicted_labels):\n",
    "        raise ValueError(\"Length of true_labels and predicted_labels must be the same.\")\n",
    "\n",
    "    # Count the number of correct predictions\n",
    "    correct_predictions = sum(1 for true, predicted in zip(true_labels, predicted_labels) if true == predicted)\n",
    "\n",
    "    # Calculate accuracy as the ratio of correct predictions to total predictions\n",
    "    accuracy = correct_predictions / len(true_labels)\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = myclassifier(x,X_test,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
